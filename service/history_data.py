# å†å²è¡Œæƒ…
import streamlit as st
import akshare as ak
import logging
from typing import Dict, Any, List
from functools import partial
import pandas as pd
from sqlalchemy.orm import Session
from sqlalchemy import func
import streamlit_echarts

from enums.patterns import Patterns
from utils.chart import ChartBuilder, calculate_macd, calculate_macd_signals, calculate_sma_signals
from utils.k_line_processor import KLineProcessor
from utils.table import format_pinyin_short

from service.stock import get_codes
from utils.convert import date_range_filter, convert_date_format
from utils.fetch_handler import create_reload_handler
from utils.message import show_message
from models.history_data import HistoryDateData
from enums.category import Category
from utils.db import get_db_session
from datetime import date, timedelta
from utils.pagination import paginate_dataframe, SearchConfig, SearchField, ActionButton, ActionConfig
from utils.session import get_session_key, SessionKeys, get_date_range
from utils.table import  format_percent, format_volume
from utils.uuid import generate_key

KEY_PREFIX = "history_data"


def show_date_page(stock):
    try:
        with get_db_session() as session:
            # æ„å»ºæŸ¥è¯¢
            query = session.query(HistoryDateData).filter(
                HistoryDateData.code == stock.code,
                HistoryDateData.removed == False
            ).order_by(HistoryDateData.date.desc())
            paginate_dataframe(
                query,
                10,
                columns_config={
                    'code': st.column_config.TextColumn('è‚¡ç¥¨ä»£ç ', help="è‚¡ç¥¨ä»£ç "),
                    'updated_at': st.column_config.DatetimeColumn('æœ€åæ›´æ–°æ—¶é—´', help="æ›´æ–°æ—¶é—´"),
                    'date': st.column_config.DateColumn('æ—¥æœŸ', help="æ—¥æœŸ"),
                    'opening': st.column_config.NumberColumn('å¼€ç›˜', help="å½“æ—¥å¼€ç›˜ä»·", format="%.3f"),
                    'closing': st.column_config.NumberColumn('æ”¶ç›˜', help="å½“æ—¥æ”¶ç›˜ä»·", format="%.3f"),
                    'highest': st.column_config.NumberColumn('æœ€é«˜', help="å½“æ—¥æœ€é«˜ä»·", format="%.3f"),
                    'lowest': st.column_config.NumberColumn('æœ€ä½', help="å½“æ—¥æœ€ä½ä»·", format="%.3f"),
                    'turnover_count': st.column_config.TextColumn('æˆäº¤é‡(æ‰‹)', help="æˆäº¤è‚¡æ•°"),
                    'turnover_amount': st.column_config.TextColumn('æˆäº¤é¢(å…ƒ)', help="æˆäº¤é‡‘é¢"),
                    'swing': st.column_config.NumberColumn('æŒ¯å¹…', help="å½“æ—¥æœ€é«˜æœ€ä½ä»·æ ¼å˜åŠ¨å¹…åº¦", format="%.2f%%"),
                    'change': st.column_config.NumberColumn('æ¶¨è·Œå¹…', help="æ¶¨è·Œå¹…",format="%.2f%%"),
                    'change_amount': st.column_config.NumberColumn('æ¶¨è·Œé¢(å…ƒ)', help="ä»·æ ¼å˜åŠ¨é¢", format="%.3f"),
                    'current_price': st.column_config.NumberColumn('æœ€æ–°ä»·', help="å½“å‰äº¤æ˜“ä»·æ ¼", format="%.3f"),
                    'change_percent': st.column_config.NumberColumn('æ¶¨è·Œå¹…', help="ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”", format="%.2f%%"),
                    'turnover_ratio': st.column_config.NumberColumn('æ¢æ‰‹ç‡', help="æˆäº¤è‚¡æ•°ä¸æµé€šè‚¡æ•°ä¹‹æ¯”",format="%.2f%%"),
                },
                # æ ¼å¼åŒ–å‡½æ•°
                format_funcs={
                    'turnover_count': format_volume,
                    'swing': format_percent,
                    'turnover_ratio': format_percent,
                    'change': format_percent,
                },
                search_config=SearchConfig(
                    fields=[
                        SearchField(
                            field="start_date",
                            label="å¼€å§‹æ—¥æœŸ",
                            type="date",
                            default=date.today() - timedelta(days=30),
                            max_date=date.today(),
                            placeholder="è¾“å…¥å¼€å§‹æ—¥æœŸ",
                            filter_func=lambda q, v: date_range_filter(q, 'start_date', v)  # æ·»åŠ è¿‡æ»¤å‡½æ•°
                        ),
                        SearchField(
                            field="end_date",
                            label="ç»“æŸæ—¥æœŸ",
                            type="date",
                            default=date.today(),
                            max_date=date.today(),
                            placeholder="è¾“å…¥ç»“æŸæ—¥æœŸ",
                            filter_func=lambda q, v: date_range_filter(q, 'end_date', v)  # æ·»åŠ è¿‡æ»¤å‡½æ•°
                        )
                    ],
                    layout=[1, 1, 1, 1]
                ),
                action_config=ActionConfig(
                    buttons=[
                        ActionButton(
                            icon="ğŸ™",
                            label="æ›´æ–°",
                            handler=partial(reload_by_code_date, category=stock.category, code=stock.code),
                            type="primary"
                        ),
                    ],
                    layout=[1, 0.1]  # æ¯ä¸ªæŒ‰é’®å ä¸€åˆ—
                ),
                title=f'{stock.category} {stock.code} ({stock.name})',
                key_prefix=get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{stock.code}_date', category=stock.category),
            )
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{str(e)}")


def show_chart_page(stock):
    try:
        with get_db_session() as session:
            # è·å–è¯¥è‚¡ç¥¨çš„æœ€æ—©å’Œæœ€æ™šæ—¥æœŸ
            date_range = session.query(
                func.min(HistoryDateData.date),
                func.max(HistoryDateData.date)
            ).filter(
                HistoryDateData.code == stock.code,
                HistoryDateData.removed == False
            ).first()

            if not date_range or None in date_range:
                st.warning("æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
                return

            min_date, max_date = date_range
            default_start_date = max(max_date - timedelta(days=90), min_date)

            # ä½¿ç”¨å›ºå®šçš„ key å‰ç¼€æ¥ä¿æŒæ—¥æœŸé€‰æ‹©å™¨çŠ¶æ€
            chart_key_prefix = f"chart_page_{stock.code}"

            key_prefix = get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{stock.code}_chart',category=stock.category)
            start_date_key = f"{key_prefix}_start_date"
            end_date_key = f"{key_prefix}_end_date"

            if start_date_key not in st.session_state:
                st.session_state[start_date_key] = default_start_date
            if end_date_key not in st.session_state:
                st.session_state[end_date_key] = max_date

            # æ·»åŠ æ—¥æœŸé€‰æ‹©å™¨
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input(
                    "å¼€å§‹æ—¥æœŸ",
                    min_value=min_date,
                    max_value=max_date,
                    key=start_date_key
                )
                if start_date != st.session_state[start_date_key]:
                    st.session_state[start_date_key] = start_date
            with col2:
                end_date = st.date_input(
                    "ç»“æŸæ—¥æœŸ",
                    min_value=min_date,
                    max_value=max_date,
                    key=end_date_key
                )
                if end_date != st.session_state[end_date_key]:
                    st.session_state[end_date_key] = end_date
            # ä»æ•°æ®åº“è·å–æ•°æ®
            query = session.query(
                HistoryDateData.date,
                HistoryDateData.opening,
                HistoryDateData.highest,
                HistoryDateData.lowest,
                HistoryDateData.closing,
                HistoryDateData.turnover_count
            ).filter(
                HistoryDateData.code == stock.code,
                HistoryDateData.removed == False,
                HistoryDateData.date >= start_date,
                HistoryDateData.date <= end_date
            ).order_by(HistoryDateData.date)

            # è¯»å–æ•°æ®åˆ°DataFrame
            df = pd.read_sql(query.statement, session.bind)

            if df.empty:
                st.warning("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
                return

            ma_lines = {}
            default_ma_periods = [5, 10, 30, 250]
            for period in default_ma_periods:
                ma_lines[f'MA{period}'] = df['closing'].rolling(window=period).mean().tolist()

            # è®¡ç®— MACD
            macd_df = calculate_macd(df)
            # è®¡ç®—ä¿¡å·æ ‡è®°
            signals = calculate_macd_signals(df, macd_df)

            # è®¡ç®—SMAä¿¡å·
            sma_signals = calculate_sma_signals(df, ma_lines)
            # åˆå¹¶ä¿¡å·
            all_signals = signals + sma_signals

            macd_dates = df['date'].astype(str).tolist()
            diff_values = macd_df['DIFF'].tolist()
            dea_values = macd_df['DEA'].tolist()
            macd_hist = macd_df['MACD_hist'].tolist()

            dates = df['date'].astype(str).tolist()
            k_line_data = df[['opening', 'closing', 'lowest', 'highest']].values.tolist()
            volumes = df['turnover_count'].tolist()
            colors = ['#ef232a' if close > open else '#14b143'
                      for open, close in zip(df['opening'], df['closing'])]

            # åˆ›å»º K çº¿å›¾
            kline = ChartBuilder.create_kline_chart(dates, k_line_data, ma_lines=ma_lines, signals=all_signals)
            volume_bar = ChartBuilder.create_volume_bar(dates, volumes, colors)
            grid = ChartBuilder.create_combined_chart(kline, volume_bar)

            # æ˜¾ç¤ºKçº¿å›¾
            streamlit_echarts.st_pyecharts(grid, theme="white", height="800px", key=f"{chart_key_prefix}_chart")
            # æ˜¾ç¤º MACD å›¾
            macd_chart = ChartBuilder.create_macd_chart(
                dates=macd_dates,
                diff=diff_values,
                dea=dea_values,
                hist=macd_hist,
                fast_period=12,
                slow_period=26,
                signal_period=9,
                title="MACD"
            )
            streamlit_echarts.st_pyecharts(macd_chart, theme="white", height="400px", key=f"{chart_key_prefix}_macd")

    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{str(e)}")

def show_process_chart_page(stock):
    try:
        with get_db_session() as session:
            # è·å–è¯¥è‚¡ç¥¨çš„æœ€æ—©å’Œæœ€æ™šæ—¥æœŸ
            date_range = session.query(
                func.min(HistoryDateData.date),
                func.max(HistoryDateData.date)
            ).filter(
                HistoryDateData.code == stock.code,
                HistoryDateData.removed == False
            ).first()

            if not date_range or None in date_range:
                st.warning("æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
                return

            min_date, max_date = date_range
            default_start_date = max(max_date - timedelta(days=90), min_date)

            # ä½¿ç”¨ç»Ÿä¸€çš„ key_prefix æ–¹å¼
            key_prefix = get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{stock.code}_process_chart', category=stock.category)

            # åˆå§‹åŒ– session state ä¸­çš„æ—¥æœŸå€¼
            start_date_key = f"{key_prefix}_start_date"
            end_date_key = f"{key_prefix}_end_date"

            if start_date_key not in st.session_state:
                st.session_state[start_date_key] = default_start_date
            if end_date_key not in st.session_state:
                st.session_state[end_date_key] = max_date

            # æ·»åŠ æ—¥æœŸé€‰æ‹©å™¨
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input(
                    "å¼€å§‹æ—¥æœŸ",
                    min_value=min_date,
                    max_value=max_date,
                    key=start_date_key
                )
                if start_date != st.session_state[start_date_key]:
                    st.session_state[start_date_key] = start_date
            with col2:
                end_date = st.date_input(
                    "ç»“æŸæ—¥æœŸ",
                    min_value=min_date,
                    max_value=max_date,
                    key=end_date_key
                )
                if end_date != st.session_state[end_date_key]:
                    st.session_state[end_date_key] = end_date

            # ä»æ•°æ®åº“è·å–æ•°æ®
            query = session.query(
                HistoryDateData.date,
                HistoryDateData.opening,
                HistoryDateData.highest,
                HistoryDateData.lowest,
                HistoryDateData.closing,
                HistoryDateData.turnover_count
            ).filter(
                HistoryDateData.code == stock.code,
                HistoryDateData.removed == False,
                HistoryDateData.date >= start_date,
                HistoryDateData.date <= end_date
            ).order_by(HistoryDateData.date)

            # è¯»å–æ•°æ®åˆ°DataFrame
            df = pd.read_sql(query.statement, session.bind)

            if df.empty:
                st.warning("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
                return

            # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
            processor = KLineProcessor()
            try:
                processor.validate_data(df)
                processed_df, contains_marks, processing_records, patterns = processor.process_klines(
                    df,
                )
                # è¯†åˆ«ç¬”
                strokes = KLineProcessor.identify_strokes(patterns, processed_df)
                # è¯†åˆ«çº¿æ®µ
                segments = KLineProcessor.identify_segments(strokes)
                # è¯†åˆ«ä¸­æ¢
                centers = KLineProcessor.identify_centers(strokes)

                processed_dates = processed_df['date'].astype(str).tolist()
                processed_k_line_data = processed_df[['opening', 'closing', 'lowest', 'highest']].values.tolist()
                processed_kline = ChartBuilder.create_kline_chart(
                    processed_dates,
                    processed_k_line_data,
                    ma_lines=None,
                    patterns=patterns,
                    strokes=strokes,
                    segments=segments,
                    centers=centers

                )
                # æ˜¾ç¤ºå›¾è¡¨
                streamlit_echarts.st_pyecharts(processed_kline,theme="white",height="500px",key=generate_key())

                # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯è¡¨æ ¼
                if processing_records:
                    st.markdown("<h6 style='margin-bottom: 10px;'>åŒ…å«å…³ç³»ä¿¡æ¯</h6>", unsafe_allow_html=True)
                    st.markdown("""
                       <div style='font-size: 12px;'>
                       - å½“ä¸¤æ ¹Kçº¿äº’ç›¸åŒ…å«æ—¶ï¼Œæ ¹æ®å‰ä¸€æ ¹Kçº¿çš„è¶‹åŠ¿å†³å®šå¤„ç†æ–¹å‘<br>
                       - å‘ä¸Šå¤„ç†ï¼šå–ä¸¤æ ¹Kçº¿ä¸­è¾ƒé«˜çš„æœ€é«˜ä»·å’Œè¾ƒé«˜çš„æœ€ä½ä»·<br>
                       - å‘ä¸‹å¤„ç†ï¼šå–ä¸¤æ ¹Kçº¿ä¸­è¾ƒä½çš„æœ€é«˜ä»·å’Œè¾ƒä½çš„æœ€ä½ä»·
                       </div>
                       """, unsafe_allow_html=True)

                    # åˆ›å»ºæ›´ç›´è§‚çš„åŒ…å«å…³ç³»DataFrame
                    # åˆ›å»ºæ›´ç›´è§‚çš„åŒ…å«å…³ç³»DataFrame
                    contains_df = pd.DataFrame([
                        {
                            'ä¸Šä¸€Kçº¿æ—¥æœŸ': record['original_k1']['date'].strftime('%Y-%m-%d'),
                            'ä¸Šä¸€Kçº¿æœ€é«˜/ä½': f"{record['original_k1']['highest']}/{record['original_k1']['lowest']}",
                            'ä¸Šä¸€Kçº¿å¼€/æ”¶ç›˜': f"{record['original_k1']['opening']}/{record['original_k1']['closing']}",
                            'å½“å‰Kçº¿æ—¥æœŸ': record['date'].strftime('%Y-%m-%d'),
                            'å½“å‰Kçº¿æœ€é«˜/ä½': f"{record['original_k2']['highest']}/{record['original_k2']['lowest']}",
                            'å½“å‰Kçº¿å¼€/æ”¶ç›˜': f"{record['original_k2']['opening']}/{record['original_k2']['closing']}",
                            'ä¸‹ä¸€Kçº¿æ—¥æœŸ': record['original_k3']['date'].strftime('%Y-%m-%d'),
                            'ä¸‹ä¸€Kçº¿æœ€é«˜/ä½': f"{record['original_k3']['highest']}/{record['original_k3']['lowest']}",
                            'ä¸‹ä¸€Kçº¿å¼€/æ”¶ç›˜': f"{record['original_k3']['opening']}/{record['original_k3']['closing']}",
                            'å¤„ç†æ–¹å‘': record['trend'],
                            'åˆå¹¶åæœ€é«˜/ä½': f"{record['new_values']['high']}/{record['new_values']['low']}"
                        }
                        for record in processing_records
                    ])

                    # æ˜¾ç¤ºåŒ…å«å…³ç³»è¡¨æ ¼
                    st.dataframe(
                        contains_df,
                        height=min(len(contains_df) * 35 + 38, 400),
                        use_container_width=True
                    )
                    st.markdown("---")
                # åŸæœ‰çš„åˆ†å‹ä¿¡æ¯è¡¨æ ¼
                if patterns:
                    st.markdown("<h6 style='margin-bottom: 10px;'>åˆ†å‹æ ‡è®°ä¿¡æ¯</h6>", unsafe_allow_html=True)
                    pattern_df = pd.DataFrame({
                        'æ—¥æœŸ': [p['date'] for p in patterns],
                        'ç±»å‹': ["â¬†é¡¶åˆ†å‹" if p['type'] == Patterns.TOP else "â¬‡åº•åˆ†å‹" for p in patterns],
                        'ä»·æ ¼': [p['value'] for p in patterns]
                    })

                    st.dataframe(
                        pattern_df,
                        height=min(len(pattern_df) * 35 + 38, 400),
                        use_container_width=True
                    )
                    st.markdown("---")
                # æ˜¾ç¤ºç¬”ä¿¡æ¯è¡¨æ ¼
                if strokes:
                    st.markdown("<h6 style='margin-bottom: 10px;'>ç¬”ä¿¡æ¯</h6>", unsafe_allow_html=True)
                    stroke_df = pd.DataFrame([
                        {
                            'èµ·å§‹æ—¥æœŸ': s['start_date'].strftime('%Y-%m-%d'),
                            'ç»“æŸæ—¥æœŸ': s['end_date'].strftime('%Y-%m-%d'),
                            'èµ·å§‹ä»·æ ¼': s['start_value'],
                            'ç»“æŸä»·æ ¼': s['end_value'],
                            'ç±»å‹': "å‘ä¸Š(S)" if s['type'] == 'up' else "å‘ä¸‹(X)",
                            'Kçº¿æ•°é‡': abs(s['end_index'] - s['start_index']) + 1
                        }
                        for s in strokes
                    ])
                    st.dataframe(
                        stroke_df,
                        height=min(len(stroke_df) * 35 + 38, 400),
                        use_container_width=True
                    )
                    st.markdown("---")
                # æ˜¾ç¤ºçº¿æ®µä¿¡æ¯è¡¨æ ¼
                if segments:
                    st.markdown("<h6 style='margin-bottom: 10px;'>çº¿æ®µä¿¡æ¯</h6>", unsafe_allow_html=True)
                    segment_df = pd.DataFrame([
                        {
                            'èµ·å§‹æ—¥æœŸ': s['start_date'].strftime('%Y-%m-%d'),
                            'ç»“æŸæ—¥æœŸ': s['end_date'].strftime('%Y-%m-%d'),
                            'èµ·å§‹ä»·æ ¼': s['start_value'],
                            'ç»“æŸä»·æ ¼': s['end_value'],
                            'ç±»å‹': "å‘ä¸Š" if s['type'] == 'up' else "å‘ä¸‹",
                            'åŒ…å«ç¬”æ•°': len(s['strokes'])
                        }
                        for s in segments
                    ])
                    st.dataframe(
                        segment_df,
                        height=min(len(segment_df) * 35 + 38, 400),
                        use_container_width=True
                    )
                    st.markdown("---")
                # æ˜¾ç¤ºä¸­æ¢ä¿¡æ¯è¡¨æ ¼
                if centers:
                    st.markdown("<h6 style='margin-bottom: 10px;'>ä¸­æ¢ä¿¡æ¯</h6>", unsafe_allow_html=True)
                    center_df = pd.DataFrame([
                        {
                            'èµ·å§‹æ—¥æœŸ': c['start_date'].strftime('%Y-%m-%d') if hasattr(c['start_date'],
                                                                                        'strftime') else str(
                                c['start_date']),
                            'ç»“æŸæ—¥æœŸ': c['end_date'].strftime('%Y-%m-%d') if hasattr(c['end_date'],
                                                                                      'strftime') else str(
                                c['end_date']),
                            'ä¸­æ¢ç±»å‹': "ä¸Šæ¶¨ä¸­æ¢" if c['type'] == 'up_center' else "ä¸‹è·Œä¸­æ¢",
                            'ä¸­æ¢é«˜ç‚¹(ZG)': round(c['ZG'], 2),
                            'ä¸­æ¢ä½ç‚¹(ZD)': round(c['ZD'], 2),
                            'ä¸­æ¢æ³¢åŠ¨æœ€é«˜ç‚¹(GG)': round(c['GG'], 2),
                            'ä¸­æ¢æ³¢åŠ¨æœ€ä½ç‚¹(DD)': round(c['DD'], 2),
                            'åŒ…å«ç¬”æ•°': len(c['strokes'])
                        }
                        for c in centers
                    ])
                    st.dataframe(
                        center_df,
                        height=min(len(center_df) * 35 + 38, 400),
                        use_container_width=True
                    )
            except ValueError as e:
                st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")


    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{str(e)}")


def show_stock_detail(stock):

    with st.expander(f"{stock.category} {stock.code} ({stock.name}-{format_pinyin_short(stock.pinyin)})   ã€Œæ•°æ®ã€", expanded=True):
        show_date_page(stock)

    with st.expander(f"{stock.category} {stock.code} ({stock.name}-{format_pinyin_short(stock.pinyin)})   ã€Œkçº¿å›¾ã€", expanded=True):
        show_chart_page(stock)

    with st.expander(f"{stock.category} {stock.code} ({stock.name}-{format_pinyin_short(stock.pinyin)})   ã€Œkçº¿å›¾-åŒ…å«&åˆ†å‹å¤„ç†ã€", expanded=True):
        show_process_chart_page(stock)


def reload_by_code_date(category: Category, code: str):
    prefix = get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{code}_date', category=category)
    date_range = get_date_range(prefix=prefix)
    if not date_range:
        return False
    start_date, end_date = date_range
    def build_filter(args: Dict[str, Any], session: Session) -> List:
        return [
            HistoryDateData.code == code,
            HistoryDateData.date >= start_date,
            HistoryDateData.date <= end_date,
        ]
    history_handler = create_reload_handler(
        model=HistoryDateData,
        fetch_func=fetch_by_date,
        unique_fields=['code', 'date'],
        build_filter=build_filter,
        with_date_range=True,
    )
    return history_handler.refresh(
        code=code,
        start_date=start_date,
        end_date=end_date)

def reload_by_category_date(category: Category, start_date: str, end_date: str):
    codes = get_codes(category)
    for code in codes:
        logging.info(f"å¼€å§‹å¤„ç†[{code}]æ•°æ®..., å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")
        def build_filter(args: Dict[str, Any], session: Session) -> List:
            return [
                HistoryDateData.code == code,
                HistoryDateData.date >= start_date,
                HistoryDateData.date <= end_date,
            ]
        history_handler = create_reload_handler(
            model=HistoryDateData,
            fetch_func=fetch_by_date,
            unique_fields=['code', 'date'],
            build_filter=build_filter,
            with_date_range=True,
        )
        history_handler.refresh_ignore_message(
            code=code,
            start_date=start_date,
            end_date=end_date)
    logging.info(f"ç»“æŸå¤„ç†[{code}]æ•°æ®..., å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")


def fetch_by_date(code: str, start_date: str, end_date: str) -> list:
    # æ‹‰å– https://akshare.akfamily.xyz/data/stock/stock.html#id22
    start_date_str = convert_date_format(start_date)
    end_date_str = convert_date_format(end_date)
    fetch_functions = {
        Category.A_SH: partial(ak.stock_zh_a_hist, symbol=code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq"),
        Category.A_SZ: partial(ak.stock_zh_a_hist, symbol=code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq"),
        Category.A_BJ: partial(ak.stock_zh_a_hist, symbol=code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq"),
        Category.X_XX: partial(ak.stock_zh_a_hist, symbol=code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq"),
    }
    try:
        category = Category.from_stock_code(code)
        if fetch_func := fetch_functions.get(category):
            logging.info(f"å¼€å§‹è·å–[{KEY_PREFIX}]æ•°æ®..., è‚¡ç¥¨:{code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")
            df = fetch_func()
            logging.info(f"æˆåŠŸè·å–[{KEY_PREFIX}]æ•°æ®..., è‚¡ç¥¨:{code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}, å…±{len(df)}æ¡è®°å½•")
            data = []
            for _, row in df.iterrows():
                try:
                    data.append(HistoryDateData(
                        category=category,
                        code=code,
                        date=row.get("æ—¥æœŸ"),
                        opening=row.get("å¼€ç›˜"),
                        closing=row.get("æ”¶ç›˜"),
                        highest=row.get("æœ€é«˜"),
                        lowest=row.get("æœ€ä½"),
                        turnover_count=row.get("æˆäº¤é‡"),
                        turnover_amount=row.get("æˆäº¤é¢"),
                        swing=row.get("æŒ¯å¹…"),
                        change=row.get("æ¶¨è·Œå¹…"),
                        change_amount=row.get("æ¶¨è·Œé¢"),
                        turnover_ratio=row.get("æ¢æ‰‹ç‡"),
                    ))

                except Exception as row_error:
                    logging.error(f"Error processing row: {row}, Error: {str(row_error)}")
                    continue
            return data
        else:
            show_message(f"ä¸æ”¯æŒçš„åˆ†ç±»: {category}", type="error")
            return None
    except Exception as e:
        logging.error(f"Error fetching data: {str(e)}")
        return None
