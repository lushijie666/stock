# å†å²è¡Œæƒ…
import os

import yfinance as yf
import akshare as ak
import pandas as pd
import streamlit as st
import logging
import threading
from collections import OrderedDict
import baostock as bs
from typing import Dict, Any, List
from functools import partial
from sqlalchemy.orm import Session
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import date, timedelta
import time
import random
from enums.category import Category
from enums.history_type import StockHistoryType

from service.stock import get_codes, get_followed_codes
from utils.background_task import BackgroundTaskExecutor
from utils.convert import date_range_filter, parse_baostock_datetime, clean_numeric_value, format_date_by_type, \
    extend_end_date
from utils.fetch_handler import create_reload_handler
from models.stock_history import get_history_model, StockHistoryW, StockHistoryD, StockHistoryM,StockHistory30M
from utils.db import get_db_session

from utils.message import show_message
from utils.pagination import paginate_dataframe, SearchConfig, SearchField, ActionButton, ActionConfig
from utils.retry import retry_with_backoff, RATE_LIMIT_RETRY_CONFIG
from utils.session import get_session_key, SessionKeys, get_date_range
from utils.table import  format_percent, format_volume
from utils.rate_limiter import get_rate_limiter, RateLimiterConfig, BALANCED_CONFIG

KEY_PREFIX = "stock_history"


def show_page(stock, t: StockHistoryType):
    try:
        model = get_history_model(t)
        with get_db_session() as session:
            # å…¶ä»–æ•°æ®æŒ‰æ—¥æœŸæ’åº
            query = session.query(model).filter(
                model.code == stock.code,
                model.removed == False
            ).order_by(model.date.desc())
            format_funcs = {
                'turnover_count': format_volume,
                'turnover_ratio': format_percent,
                'change': format_percent,
                'date': lambda x: format_date_by_type(x, t),
            }
            paginate_dataframe(
                query,
                10,
                columns_config={
                    'code': st.column_config.TextColumn('è‚¡ç¥¨ä»£ç ', help="è‚¡ç¥¨ä»£ç "),
                    'date': st.column_config.TextColumn('æ—¥æœŸï¼ˆæ—¶é—´ï¼‰', help="æ—¥æœŸ"),
                    'opening': st.column_config.NumberColumn('å¼€ç›˜', help="å½“æ—¥å¼€ç›˜ä»·", format="%.3f"),
                    'closing': st.column_config.NumberColumn('æ”¶ç›˜', help="å½“æ—¥æ”¶ç›˜ä»·", format="%.3f"),
                    'highest': st.column_config.NumberColumn('æœ€é«˜', help="å½“æ—¥æœ€é«˜ä»·", format="%.3f"),
                    'lowest': st.column_config.NumberColumn('æœ€ä½', help="å½“æ—¥æœ€ä½ä»·", format="%.3f"),
                    'turnover_count': st.column_config.TextColumn('æˆäº¤é‡(æ‰‹)', help="æˆäº¤è‚¡æ•°"),
                    'turnover_amount': st.column_config.TextColumn('æˆäº¤é¢(å…ƒ)', help="æˆäº¤é‡‘é¢"),
                    'change': st.column_config.NumberColumn('æ¶¨è·Œå¹…', help="æ¶¨è·Œå¹…", format="%.2f%%"),
                    'turnover_ratio': st.column_config.NumberColumn('æ¢æ‰‹ç‡', help="æˆäº¤è‚¡æ•°ä¸æµé€šè‚¡æ•°ä¹‹æ¯”", format="%.2f%%"),
                    'updated_at': st.column_config.DatetimeColumn('æœ€åæ›´æ–°æ—¶é—´', help="æ›´æ–°æ—¶é—´"),
                },
                # æ ¼å¼åŒ–å‡½æ•°
                format_funcs=format_funcs,
                search_config=SearchConfig(
                    fields=[
                        SearchField(
                            field="start_date",
                            label="å¼€å§‹æ—¥æœŸ",
                            type="date",
                            default=date.today() - timedelta(days=90),
                            max_date=date.today(),
                            placeholder="è¾“å…¥å¼€å§‹æ—¥æœŸ",
                            filter_func=lambda q, v: date_range_filter(q, 'start_date', v)  # æ·»åŠ è¿‡æ»¤å‡½æ•°
                        ),
                        SearchField(
                            field="end_date",
                            label="ç»“æŸæ—¥æœŸ",
                            type="date",
                            default=date.today(),
                            max_date=date.today(),
                            placeholder="è¾“å…¥ç»“æŸæ—¥æœŸ",
                            filter_func=lambda q, v: date_range_filter(q, 'end_date', v)  # æ·»åŠ è¿‡æ»¤å‡½æ•°
                        )
                    ],
                    layout=[1, 1, 1, 1]
                ),
                action_config=ActionConfig(
                    buttons=[
                        ActionButton(
                            icon="ğŸ™",
                            label="æ›´æ–°",
                            handler=partial(manual_reload_by_code, category=stock.category, code=stock.code, t=t),
                            type="primary"
                        ),
                    ],
                    layout=[1, 0.1]  # æ¯ä¸ªæŒ‰é’®å ä¸€åˆ—
                ),

                title=f'{stock.category} {stock.code} ({stock.name}) - [{t.text}]',
                key_prefix=get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{stock.code}_{t}_date', category=stock.category),
            )
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{str(e)}")


def show_detail(stock):
    t = st.radio(
        "é€‰æ‹©æ—¶é—´å‘¨æœŸ",
        ["å¤©", "å‘¨", "æœˆ", "30åˆ†é’Ÿ"],
        horizontal=True,
        key=f"{KEY_PREFIX}_{stock.code}_radio",
        label_visibility="collapsed"
    )
    handlers = {
        "å¤©": lambda:  show_page(stock, StockHistoryType.D),
        "å‘¨": lambda:  show_page(stock, StockHistoryType.W),
        "æœˆ": lambda:  show_page(stock, StockHistoryType.M),
        "30åˆ†é’Ÿ": lambda:  show_page(stock, StockHistoryType.THIRTY_M),
    }
    handlers.get(t, lambda: None)()

def manual_reload_by_code(category: Category, code: str, t: StockHistoryType):
    prefix = get_session_key(SessionKeys.PAGE, prefix=f'{KEY_PREFIX}_{code}_{t}_date', category=category)
    date_range = get_date_range(prefix=prefix)
    if not date_range:
        return
    start_date, end_date = date_range
    handler = _create_history_handler(t)
    handler.refresh(
        code=code,
        start_date=start_date,
        end_date=end_date,
        t=t)

def reload_by_code(code: str, start_date: str, end_date: str, t: StockHistoryType, ignore_message: bool = False):
    handler = _create_history_handler(t)
    if ignore_message:
        handler.refresh_ignore_message(
            code=code,
            start_date=start_date,
            end_date=end_date,
            t=t)
    else:
        handler.refresh(
            code=code,
            start_date=start_date,
            end_date=end_date,
            t=t)

def reload_by_category(category: Category, start_date: str, end_date: str, t: StockHistoryType, is_all: bool, ignore_message: bool = False):
    codes = get_codes(category)
    if not is_all:
        codes = get_followed_codes(category)
    handler = _create_history_handler(t)
    for code in codes:
        if ignore_message:
            handler.refresh_ignore_message(
                code=code,
                start_date=start_date,
                end_date=end_date,
                t=t)
        else:
            handler.refresh(
                code=code,
                start_date=start_date,
                end_date=end_date,
                t=t)
def _create_history_handler(t: StockHistoryType):
    model = get_history_model(t)
    def build_filter(args: Dict[str, Any], session: Session) -> List:
        code = args.get('code')
        start_date = args.get('start_date')
        end_date = args.get('end_date')
        end_date = extend_end_date(end_date)
        return [
            model.code == code,
            model.date >= start_date,
            model.date <= end_date,
        ]

    return create_reload_handler(
        model=model,
        fetch_func=fetch,
        unique_fields=['code', 'date'],
        build_filter=build_filter,
        with_date_range=True
    )


def fetch(code: str, start_date: str, end_date: str, t: StockHistoryType) -> list:
    # æ‹‰å– http://www.baostock.com/mainContent?file=stockKData.md
    category = Category.from_stock_code(code)
    if category == Category.X_XX or category == Category.A_BJ: # æš‚ä¸æ”¯æŒè¿™ä¸¤ç§
        logging.info(f"è·å–[{KEY_PREFIX}]æ•°æ®æš‚ä¸æ”¯æŒ..., åˆ†ç±»: {category.fullText}, è‚¡ç¥¨: {code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")
        return []
    if category == Category.US_XX:
        return _fetch_us_stock_data(code, start_date, end_date, t)
    return _fetch_a_stock_data(code, start_date, end_date, t)



_baostock_lock = threading.Lock()
def _fetch_a_stock_data(code: str, start_date: str, end_date: str, t: StockHistoryType) -> list:
    # æ‹‰å– http://www.baostock.com/mainContent?file=stockKData.md
    category = Category.from_stock_code(code)
    fields = {
        StockHistoryType.D: "date,code,open,high,low,close,volume,amount,adjustflag,turn,pctChg",
        StockHistoryType.W: "date,code,open,high,low,close,volume,amount,adjustflag,turn,pctChg",
        StockHistoryType.M: "date,code,open,high,low,close,volume,amount,adjustflag,turn,pctChg",
        StockHistoryType.THIRTY_M: "date,time,code,open,high,low,close,volume,amount,adjustflag"
    }
    try:
        # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿baostock APIçš„è°ƒç”¨æ˜¯çº¿ç¨‹å®‰å…¨çš„
        with _baostock_lock:
            lg = bs.login()
            logging.info(f"ç™»å½•ç»“æœä¸º, code: {lg.error_code}, msg: {lg.error_msg}")

            logging.info(
                f"å¼€å§‹è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®..., è‚¡ç¥¨:{code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")
            fields = fields.get(t)
            rs = bs.query_history_k_data_plus(category.get_full_code(code, "."),
                                              fields,
                                              start_date=start_date, end_date=end_date, frequency=t.bs_frequency,
                                              adjustflag="1")
            logging.info(
                f"è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®ç»“æœä¸º..., åˆ†ç±»: {category.fullText}, è‚¡ç¥¨: {code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}, code: {rs.error_code}, msg: {rs.error_msg}")
            if rs.error_code != '0':
                logging.error(
                    f"è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®å¤±è´¥..., åˆ†ç±»: {category.fullText}, è‚¡ç¥¨: {code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}, code: {rs.error_code}, msg: {rs.error_msg}")
                return None
            data_list = []
            while (rs.error_code == '0') & rs.next():
                row_data = rs.get_row_data()
                logging.info(
                    f"è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®ä¸º..., åˆ†ç±»: {category.fullText}, è‚¡ç¥¨:{code}, æ—¥æœŸ: {row_data[0]}, ä¿¡æ¯ä¸º: {row_data}")
                model_instance = None
                if t == StockHistoryType.W:
                    model_instance = StockHistoryW(
                        category=category,
                        code=code,
                        date=row_data[0],
                        opening=clean_numeric_value(row_data[2]),
                        highest=clean_numeric_value(row_data[3]),
                        lowest=clean_numeric_value(row_data[4]),
                        closing=clean_numeric_value(row_data[5]),
                        turnover_count=clean_numeric_value(row_data[6]),
                        turnover_amount=clean_numeric_value(row_data[7]),
                        turnover_ratio=clean_numeric_value(row_data[9]),
                        change=clean_numeric_value(row_data[10])
                    )
                elif t == StockHistoryType.M:
                    model_instance = StockHistoryM(
                        category=category,
                        code=code,
                        date=row_data[0],
                        opening=clean_numeric_value(row_data[2]),
                        highest=clean_numeric_value(row_data[3]),
                        lowest=clean_numeric_value(row_data[4]),
                        closing=clean_numeric_value(row_data[5]),
                        turnover_count=clean_numeric_value(row_data[6]),
                        turnover_amount=clean_numeric_value(row_data[7]),
                        turnover_ratio=clean_numeric_value(row_data[9]),
                        change=clean_numeric_value(row_data[10])
                    )
                elif t == StockHistoryType.THIRTY_M:
                    model_instance = StockHistory30M(
                        category=category,
                        code=code,
                        date=parse_baostock_datetime(row_data[1]),
                        opening=clean_numeric_value(row_data[3]),
                        highest=clean_numeric_value(row_data[4]),
                        lowest=clean_numeric_value(row_data[5]),
                        closing=clean_numeric_value(row_data[6]),
                        turnover_count=clean_numeric_value(row_data[7]),
                        turnover_amount=clean_numeric_value(row_data[8]),
                        # turnover_ratio=row_data[9],
                        # change=row_data[9]
                    )
                else:
                    model_instance = StockHistoryD(
                        category=category,
                        code=code,
                        date=row_data[0],
                        opening=clean_numeric_value(row_data[2]),
                        highest=clean_numeric_value(row_data[3]),
                        lowest=clean_numeric_value(row_data[4]),
                        closing=clean_numeric_value(row_data[5]),
                        turnover_count=clean_numeric_value(row_data[6]),
                        turnover_amount=clean_numeric_value(row_data[7]),
                        turnover_ratio=clean_numeric_value(row_data[9]),
                        change=clean_numeric_value(row_data[10])
                    )
                data_list.append(model_instance)
            logging.info(
                f"è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®æˆåŠŸ..., åˆ†ç±»: {category.fullText}, è‚¡ç¥¨: {code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}, å…±{len(data_list)}æ¡è®°å½•")
            bs.logout()
        return data_list
    except Exception as e:
        logging.error(f"è·å–[{KEY_PREFIX}][{t.text}]æ•°æ®å¼‚å¸¸: {str(e)}")
        # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿèƒ½æ­£ç¡®ç™»å‡º
        with _baostock_lock:
            bs.logout()
        return data_list



# ç¾è‚¡æ•°æ®è·å–ä½¿ç”¨é€šç”¨é™æµå™¨
# ä½¿ç”¨å¹³è¡¡æ¨¡å¼é…ç½®ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ä¸º AGGRESSIVE_CONFIG æˆ– CONSERVATIVE_CONFIGï¼‰
_us_stock_limiter = get_rate_limiter("akshare_us_stock", BALANCED_CONFIG)


def _aggregate_minute_to_30min(df: pd.DataFrame) -> pd.DataFrame:
    """
    å°†1åˆ†é’Ÿæ•°æ®èšåˆä¸º30åˆ†é’Ÿæ•°æ®

    Args:
        df: 1åˆ†é’Ÿæ•°æ®ï¼ŒåŒ…å«åˆ—ï¼šæ—¶é—´ã€å¼€ç›˜ã€æ”¶ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æˆäº¤é‡ã€æˆäº¤é¢

    Returns:
        30åˆ†é’Ÿèšåˆæ•°æ®
    """
    if df is None or df.empty:
        return df

    # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime ç±»å‹
    df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])

    # è®¾ç½®æ—¶é—´ä¸ºç´¢å¼•
    df.set_index('æ—¶é—´', inplace=True)

    # æŒ‰30åˆ†é’Ÿé‡é‡‡æ ·
    # å¼€ç›˜ä»·ï¼šå–ç¬¬ä¸€ä¸ªå€¼
    # æœ€é«˜ä»·ï¼šå–æœ€å¤§å€¼
    # æœ€ä½ä»·ï¼šå–æœ€å°å€¼
    # æ”¶ç›˜ä»·ï¼šå–æœ€åä¸€ä¸ªå€¼
    # æˆäº¤é‡ï¼šæ±‚å’Œ
    # æˆäº¤é¢ï¼šæ±‚å’Œ
    agg_rules = {
        'å¼€ç›˜': 'first',
        'æœ€é«˜': 'max',
        'æœ€ä½': 'min',
        'æ”¶ç›˜': 'last',
        'æˆäº¤é‡': 'sum',
        'æˆäº¤é¢': 'sum',
    }

    # å¦‚æœæœ‰æœ€æ–°ä»·ï¼Œä¹Ÿèšåˆ
    if 'æœ€æ–°ä»·' in df.columns:
        agg_rules['æœ€æ–°ä»·'] = 'last'

    # é‡é‡‡æ ·ä¸º30åˆ†é’Ÿ
    df_30min = df.resample('30min').agg(agg_rules)

    # ç§»é™¤ç©ºå€¼è¡Œï¼ˆå¯èƒ½åœ¨æŸäº›æ—¶é—´æ®µæ²¡æœ‰äº¤æ˜“ï¼‰
    df_30min = df_30min.dropna()

    # é‡ç½®ç´¢å¼•ï¼Œå°†æ—¶é—´åˆ—æ¢å¤
    df_30min.reset_index(inplace=True)

    # å¤„ç†å¼€ç›˜ä»·ä¸º0çš„æƒ…å†µï¼šç”¨å‰ä¸€æ¡è®°å½•çš„æ”¶ç›˜ä»·ä»£æ›¿
    # ä½¿ç”¨ shift() è·å–å‰ä¸€è¡Œçš„æ”¶ç›˜ä»·
    df_30min['å‰æ”¶ç›˜'] = df_30min['æ”¶ç›˜'].shift(1)

    # è®°å½•éœ€è¦ä¿®å¤çš„æ•°é‡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    zero_open_count = (df_30min['å¼€ç›˜'] == 0).sum()

    # å½“å¼€ç›˜ä»·ä¸º0æ—¶ï¼Œä½¿ç”¨å‰ä¸€æ¡çš„æ”¶ç›˜ä»·
    # ç¬¬ä¸€æ¡è®°å½•å¦‚æœå¼€ç›˜ä»·ä¸º0ï¼Œåˆ™ä½¿ç”¨å½“å‰çš„æ”¶ç›˜ä»·ï¼ˆå› ä¸ºæ²¡æœ‰å‰ä¸€æ¡ï¼‰
    df_30min['å¼€ç›˜'] = df_30min.apply(
        lambda row: row['å‰æ”¶ç›˜'] if row['å¼€ç›˜'] == 0 and pd.notna(row['å‰æ”¶ç›˜'])
                    else (row['æ”¶ç›˜'] if row['å¼€ç›˜'] == 0 else row['å¼€ç›˜']),
        axis=1
    )

    # åˆ é™¤ä¸´æ—¶åˆ—
    df_30min.drop(columns=['å‰æ”¶ç›˜'], inplace=True)

    if zero_open_count > 0:
        logging.info(f"ä¿®å¤äº† {zero_open_count} æ¡å¼€ç›˜ä»·ä¸º0çš„è®°å½•ï¼ˆä½¿ç”¨å‰ä¸€æ¡æ”¶ç›˜ä»·ï¼‰")

    logging.info(f"èšåˆåˆ†é’Ÿæ•°æ®: åŸå§‹ {len(df)} æ¡ â†’ 30åˆ†é’Ÿ {len(df_30min)} æ¡")

    return df_30min


def _fetch_us_stock_data(code: str, start_date: str, end_date: str, t: StockHistoryType) -> list:
    """ä½¿ç”¨ akshare æŠ“å–ç¾è‚¡æ•°æ®ï¼ˆä¸œè´¢æ•°æ®æºï¼Œå›½å†…ç½‘ç»œå‹å¥½ï¼‰"""
    def _fetch_data():
        # ä½¿ç”¨é€šç”¨é™æµå™¨ï¼šè¯·æ±‚å‰æ™ºèƒ½ç­‰å¾…
        _us_stock_limiter.wait_before_request()

        logging.info(f"å¼€å§‹è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]æ•°æ®..., è‚¡ç¥¨:{code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")

        # akshare éœ€è¦å¸¦å‰ç¼€çš„è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 105.AAPLï¼‰
        # æ ¹æ®æµ‹è¯•ï¼Œå¤§éƒ¨åˆ†ç¾è‚¡ä½¿ç”¨ 105 å‰ç¼€
        symbol = f"105.{code}"

        try:
            # 30åˆ†é’Ÿæ•°æ®ä½¿ç”¨åˆ†æ—¶æ¥å£
            if t == StockHistoryType.THIRTY_M:
                # stock_us_hist_min_em è¿”å›1åˆ†é’Ÿæ•°æ®ï¼Œéœ€è¦æŒ‡å®šæ—¶é—´èŒƒå›´
                # æ ¼å¼: YYYY-MM-DD HH:MM:SS
                start_datetime = f"{start_date} 00:00:00"
                end_datetime = f"{end_date} 23:59:59"

                df = ak.stock_us_hist_min_em(
                    symbol=symbol,
                    start_date=start_datetime,
                    end_date=end_datetime
                )

                if df is None or df.empty:
                    logging.warning(f"è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]åˆ†æ—¶æ•°æ®ä¸ºç©º, è‚¡ç¥¨: {code}, symbol: {symbol}")
                    _us_stock_limiter.handle_success()
                    return []

                # å°†1åˆ†é’Ÿæ•°æ®èšåˆä¸º30åˆ†é’Ÿæ•°æ®
                df = _aggregate_minute_to_30min(df)

            else:
                # æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿ä½¿ç”¨ stock_us_hist æ¥å£
                period_map = {
                    StockHistoryType.D: "daily",
                    StockHistoryType.W: "weekly",
                    StockHistoryType.M: "monthly",
                }

                period = period_map.get(t, "daily")

                # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD -> YYYYMMDD
                start_date_fmt = start_date.replace('-', '')
                end_date_fmt = end_date.replace('-', '')

                df = ak.stock_us_hist(
                    symbol=symbol,
                    period=period,
                    start_date=start_date_fmt,
                    end_date=end_date_fmt,
                    adjust="hfq"
                )
            if df is None or df.empty:
                logging.warning(f"è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]æ•°æ®ä¸ºç©º, è‚¡ç¥¨: {code}, symbol: {symbol}")
                # æ•°æ®ä¸ºç©ºä¹Ÿç®—æˆåŠŸï¼ˆå¯èƒ½æ˜¯è¯¥æ—¶é—´æ®µæ²¡æœ‰äº¤æ˜“æ•°æ®ï¼‰
                _us_stock_limiter.handle_success()
                return []

            # è¯·æ±‚æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°
            _us_stock_limiter.handle_success()

            data_list = []
            for index, row in df.iterrows():
                # æ ¹æ®ä¸åŒçš„æ—¶é—´ç±»å‹åˆ›å»ºç›¸åº”çš„æ¨¡å‹å®ä¾‹
                model_instance = None

                # 30åˆ†é’Ÿæ•°æ®çš„å­—æ®µåä¸åŒï¼ˆæ¥è‡ªåˆ†æ—¶æ¥å£ï¼‰
                if t == StockHistoryType.THIRTY_M:
                    # åˆ†æ—¶æ¥å£è¿”å›å­—æ®µï¼šæ—¶é—´ã€å¼€ç›˜ã€æ”¶ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æˆäº¤é‡ã€æˆäº¤é¢
                    # æ³¨æ„ï¼šæ—¶é—´åˆ—å¯èƒ½æ˜¯ç´¢å¼•ï¼Œä¹Ÿå¯èƒ½æ˜¯æ™®é€šåˆ—
                    if 'æ—¶é—´' in row:
                        date_str = str(row['æ—¶é—´'])
                    else:
                        date_str = str(index)

                    model_instance = StockHistory30M(
                        category=Category.US_XX,
                        code=code,
                        date=date_str,
                        opening=clean_numeric_value(row['å¼€ç›˜']),
                        highest=clean_numeric_value(row['æœ€é«˜']),
                        lowest=clean_numeric_value(row['æœ€ä½']),
                        closing=clean_numeric_value(row['æ”¶ç›˜']),
                        turnover_count=clean_numeric_value(row['æˆäº¤é‡']),
                        turnover_amount=clean_numeric_value(row.get('æˆäº¤é¢')),
                    )
                else:
                    # æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿æ•°æ®å­—æ®µï¼šæ—¥æœŸã€å¼€ç›˜ã€æ”¶ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æˆäº¤é‡ã€æˆäº¤é¢ã€æŒ¯å¹…ã€æ¶¨è·Œå¹…ã€æ¶¨è·Œé¢ã€æ¢æ‰‹ç‡
                    date_str = str(row['æ—¥æœŸ'])

                    if t == StockHistoryType.W:
                        model_instance = StockHistoryW(
                            category=Category.US_XX,
                            code=code,
                            date=date_str,
                            opening=clean_numeric_value(row['å¼€ç›˜']),
                            highest=clean_numeric_value(row['æœ€é«˜']),
                            lowest=clean_numeric_value(row['æœ€ä½']),
                            closing=clean_numeric_value(row['æ”¶ç›˜']),
                            turnover_count=clean_numeric_value(row['æˆäº¤é‡']),
                            turnover_amount=clean_numeric_value(row['æˆäº¤é¢']),
                            turnover_ratio=clean_numeric_value(row['æ¢æ‰‹ç‡']),
                            change=clean_numeric_value(row['æ¶¨è·Œå¹…'])
                        )
                    elif t == StockHistoryType.M:
                        model_instance = StockHistoryM(
                            category=Category.US_XX,
                            code=code,
                            date=date_str,
                            opening=clean_numeric_value(row['å¼€ç›˜']),
                            highest=clean_numeric_value(row['æœ€é«˜']),
                            lowest=clean_numeric_value(row['æœ€ä½']),
                            closing=clean_numeric_value(row['æ”¶ç›˜']),
                            turnover_count=clean_numeric_value(row['æˆäº¤é‡']),
                            turnover_amount=clean_numeric_value(row['æˆäº¤é¢']),
                            turnover_ratio=clean_numeric_value(row['æ¢æ‰‹ç‡']),
                            change=clean_numeric_value(row['æ¶¨è·Œå¹…'])
                        )
                    else:  # æ—¥çº¿æ•°æ®
                        model_instance = StockHistoryD(
                            category=Category.US_XX,
                            code=code,
                            date=date_str,
                            opening=clean_numeric_value(row['å¼€ç›˜']),
                            highest=clean_numeric_value(row['æœ€é«˜']),
                            lowest=clean_numeric_value(row['æœ€ä½']),
                            closing=clean_numeric_value(row['æ”¶ç›˜']),
                            turnover_count=clean_numeric_value(row['æˆäº¤é‡']),
                            turnover_amount=clean_numeric_value(row['æˆäº¤é¢']),
                            turnover_ratio=clean_numeric_value(row['æ¢æ‰‹ç‡']),
                            change=clean_numeric_value(row['æ¶¨è·Œå¹…'])
                        )
                data_list.append(model_instance)
            logging.info(
                f"è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]æ•°æ®æˆåŠŸ..., è‚¡ç¥¨: {code}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}, å…±{len(data_list)}æ¡è®°å½•")
            return data_list

        except Exception as e:
            # è¯·æ±‚å¤±è´¥ï¼Œè§¦å‘å†·å´æœºåˆ¶
            _us_stock_limiter.handle_failure()
            logging.error(f"è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]æ•°æ®å¼‚å¸¸: {str(e)}, è‚¡ç¥¨: {code}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©é‡è¯•æœºåˆ¶å¤„ç†

    try:
        # ä½¿ç”¨é‡è¯•å·¥å…·å¤„ç†é¢‘ç‡é™åˆ¶é—®é¢˜
        return retry_with_backoff(
            func=_fetch_data,
            max_retries=RATE_LIMIT_RETRY_CONFIG.max_retries,
            base_delay=RATE_LIMIT_RETRY_CONFIG.base_delay,
            max_delay=RATE_LIMIT_RETRY_CONFIG.max_delay,
            backoff_factor=RATE_LIMIT_RETRY_CONFIG.backoff_factor,
            jitter=RATE_LIMIT_RETRY_CONFIG.jitter,
            exceptions=(Exception,),
            logger=logging
        )
    except Exception as e:
        logging.error(f"è·å–ç¾è‚¡[{KEY_PREFIX}][{t.text}]æ•°æ®å¼‚å¸¸: {str(e)}")
        return []

def sync(t: StockHistoryType, is_all: bool, start_date=None, end_date=None) -> Dict[str, Any]:
    # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨
    success_count = 0
    failed_count = 0
    processed_count = 0
    count_lock = threading.Lock()
    
    # è®°å½•æ€»å¼€å§‹æ—¶é—´
    total_start_time = time.time()
    
    # å¦‚æœæ²¡æœ‰æä¾›æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸ºè¿‘7å¤©
    if not end_date:
        end_date = date.today()
    if not start_date:
        start_date = end_date - timedelta(days=7)

    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    logging.info(f"å¼€å§‹åŒæ­¥[{KEY_PREFIX}][{t.text}]æ•°æ®, æ—¶é—´èŒƒå›´ï¼š{start_date_str} è‡³ {end_date_str}")
    
    # æ”¶é›†æ‰€æœ‰éœ€è¦åŒæ­¥çš„ä»»åŠ¡
    tasks = []
    categories = Category.get_all()

    for category in categories:
        logging.info(f"å¼€å§‹åŒæ­¥[{KEY_PREFIX}][{t.text}]æ•°æ®ï¼Œåˆ†ç±»: {category.fullText}")
        codes = get_codes(category)
        if not is_all:
            codes = get_followed_codes(category)

        # ä¸ºæ¯ä¸ªè‚¡ç¥¨ä»£ç åˆ›å»ºä»»åŠ¡
        for code in codes:
            tasks.append((code, category, start_date_str, end_date_str, t))

    # è·å–æ€»ä»»åŠ¡æ•°
    total_tasks = len(tasks)
    logging.info(f"åŒæ­¥[{KEY_PREFIX}][{t.text}]æ•°æ®, æ€»å…±æœ‰ {total_tasks} ä¸ªè‚¡ç¥¨éœ€è¦åŒæ­¥")

    # å®šä¹‰å•ä¸ªè‚¡ç¥¨åŒæ­¥çš„å·¥ä½œå‡½æ•°
    def sync_single_stock(task):
        code, category, start_date_str, end_date_str, t = task
        nonlocal success_count, failed_count, processed_count

        # è®°å½•å•ä¸ªè‚¡ç¥¨å¼€å§‹æ—¶é—´
        stock_start_time = time.time()

        try:
            # æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
            with get_db_session() as session:
                reload_by_code(code, start_date_str, end_date_str, t, True)

            # è®¡ç®—å•ä¸ªè‚¡ç¥¨å¤„ç†è€—æ—¶
            stock_elapsed_time = time.time() - stock_start_time

            with count_lock:
                success_count += 1
                processed_count += 1
                remaining = total_tasks - processed_count
            logging.info(f"è‚¡ç¥¨: {code} å¤„ç†[{KEY_PREFIX}][{t.text}]æ•°æ®å®Œæˆï¼Œè€—æ—¶: {stock_elapsed_time:.2f}ç§’ï¼Œè¿˜å‰© {remaining} ä¸ªè‚¡ç¥¨")
            return True, code, None
        except Exception as e:
            # è®¡ç®—å•ä¸ªè‚¡ç¥¨å¤„ç†è€—æ—¶
            stock_elapsed_time = time.time() - stock_start_time
            with count_lock:
                failed_count += 1
                processed_count += 1
                remaining = total_tasks - processed_count
            error_msg = str(e)
            logging.error(f"è‚¡ç¥¨: {code} å¤„ç†[{KEY_PREFIX}][{t.text}]æ•°æ®æ—¶å‡ºé”™: {error_msg}ï¼Œè€—æ—¶: {stock_elapsed_time:.2f}ç§’ï¼Œè¿˜å‰© {remaining} ä¸ªè‚¡ç¥¨")
            return False, code, error_msg

    # é˜²å°ç­–ç•¥ï¼šæ ¹æ®åˆ†ç±»åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
    # ç¾è‚¡ä½¿ç”¨è¾ƒä½çš„å¹¶å‘æ•°ï¼ˆå› ä¸º akshare å®¹æ˜“è¢«é™æµï¼‰
    # Aè‚¡ä½¿ç”¨è¾ƒé«˜çš„å¹¶å‘æ•°ï¼ˆå› ä¸º baostock ç›¸å¯¹ç¨³å®šï¼‰
    us_stock_count = sum(1 for task in tasks if task[1] == Category.US_XX)
    if us_stock_count > 0:
        # å¦‚æœåŒ…å«ç¾è‚¡ï¼Œä½¿ç”¨ä½å¹¶å‘ï¼ˆä¸²è¡Œæˆ–2-3ä¸ªçº¿ç¨‹ï¼‰
        max_workers = min(3, len(tasks) if tasks else 1)
        logging.info(f"æ£€æµ‹åˆ° {us_stock_count} åªç¾è‚¡ï¼Œé™ä½å¹¶å‘æ•°è‡³ {max_workers} ä»¥é˜²æ­¢è¢«å°")
    else:
        # çº¯Aè‚¡æ•°æ®ï¼Œä½¿ç”¨æ­£å¸¸å¹¶å‘
        max_workers = min(30, len(tasks) if tasks else 1)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_task = {executor.submit(sync_single_stock, task): task for task in tasks}
        
        # å¤„ç†ä»»åŠ¡ç»“æœï¼ˆç§»é™¤æ‰€æœ‰UIæ¶ˆæ¯æ˜¾ç¤ºï¼‰
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            code = task[0]
            try:
                # åªè·å–ç»“æœï¼Œä¸æ˜¾ç¤ºä»»ä½•æ¶ˆæ¯
                future.result()
            except Exception as e:
                with count_lock:
                    failed_count += 1
                    processed_count += 1
                    remaining = total_tasks - processed_count
                error_msg = f"è‚¡ç¥¨: {code} ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}ï¼Œè¿˜å‰© {remaining} ä¸ªè‚¡ç¥¨"
                logging.error(error_msg)
    
    # è®¡ç®—æ€»è€—æ—¶
    total_elapsed_time = time.time() - total_start_time
    logging.info(f"å®ŒæˆåŒæ­¥[{KEY_PREFIX}][{t.text}]æ•°æ®, æ—¶é—´èŒƒå›´ï¼š{start_date_str} è‡³ {end_date_str}")
    logging.info(f"æ€»å¤„ç†è‚¡ç¥¨æ•°: {total_tasks}, æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
    logging.info(f"æ€»è€—æ—¶: {total_elapsed_time:.2f}ç§’, å¹³å‡æ¯ä¸ªè‚¡ç¥¨è€—æ—¶: {total_elapsed_time/total_tasks:.2f}ç§’")
    return {
        "success_count": success_count,
        "failed_count": failed_count
    }

